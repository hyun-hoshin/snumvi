{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVD7911EVcWI",
    "outputId": "2783c3a4-855a-4b2b-86c0-297b7b31b9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  3 02:01:41 KST 2023\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:14:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    24W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    24W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:39:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    68W / 250W |   3795MiB / 32510MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    26W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    1   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    2   N/A  N/A      7984      C   python                           3791MiB |\n",
      "|    3   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    4   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    5   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    6   N/A  N/A      7984      C   python                              0MiB |\n",
      "|    7   N/A  N/A      7984      C   python                              0MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNnKTuzBgKZm",
    "outputId": "8b7c3607-768e-4222-d4c0-82806f5a1264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 1.7.1+cu110\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /home/aistore3/.conda/envs/snuimageseg/lib/python3.8/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 5.0.0\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.0\n",
      "gdown version: 4.6.0\n",
      "TorchVision version: 0.8.2+cu110\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: 1.4.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.5.2\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.25.1\n",
      "mlflow version: 2.1.1\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()\n",
    "set_determinism(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"marked\"\n",
    "uncropped_dir = \"nifti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "patients = sorted(glob.glob(os.path.join(uncropped_dir, \"*.nii.gz\")))\n",
    "print(len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       v_center  h_center  l_center\n",
      "patID                              \n",
      "1            88       133        60\n",
      "2           113       185        67\n",
      "3            81       209        39\n",
      "7           175       280        78\n",
      "10          180       259        40\n",
      "...         ...       ...       ...\n",
      "348         104       212        52\n",
      "349         155       176        43\n",
      "350         190       179        60\n",
      "351         154       125        53\n",
      "352         270       326        71\n",
      "\n",
      "[231 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "patient_data = pd.read_excel(\"new_nifti_center2.xlsx\", usecols=['patID', 'v_center', 'h_center', 'l_center']).set_index(\"patID\").dropna().astype('int')\n",
    "print(patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nii_loader(filename) :\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    nimg = nib.load(filename)\n",
    "    return nimg.get_fdata(), nimg.affine, nimg.header\n",
    "\n",
    "def mark_nifti(patients, idx, patient_data):\n",
    "    image = patients[idx]\n",
    "    image_data, image_affine, image_header = nii_loader(image)\n",
    "    image_shape = image_data.shape\n",
    "    \n",
    "    patID = int(os.path.basename(image).split('.')[0])\n",
    "    center_coords = patient_data.loc[patID, \"v_center\":\"l_center\"]\n",
    "    target_layer = center_coords[2]\n",
    "    target_image = np.rot90(image_data[:,:,target_layer], 1)\n",
    "    \n",
    "    mark_size = image_shape[0]//5\n",
    "    x = center_coords[0] - mark_size//2\n",
    "    y = image_shape[1] - center_coords[1] - mark_size//2\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(target_image, cmap='gray')\n",
    "    ax.add_patch(patches.Rectangle((x, y), mark_size, mark_size, edgecolor = 'red', fill=False))\n",
    "    ax.text(image_shape[0]*0.3, image_shape[1]*0.85, f'[patID] {patID}', color='white')\n",
    "    ax.text(image_shape[0]*0.3, image_shape[1]*0.9, f'[dimension] {image_shape}', color='white')\n",
    "    plt.savefig(os.path.join(image_dir, str(patID) + '_layer' + str(center_coords[2]) + '.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process nifti/100.nii.gz\n",
      "Failed to process nifti/162.nii.gz\n",
      "Failed to process nifti/23.nii.gz\n",
      "Failed to process nifti/233.nii.gz\n",
      "Failed to process nifti/286.nii.gz\n",
      "Failed to process nifti/288.nii.gz\n",
      "Failed to process nifti/290.nii.gz\n",
      "Failed to process nifti/309.nii.gz\n",
      "Failed to process nifti/315.nii.gz\n",
      "Failed to process nifti/322.nii.gz\n",
      "Failed to process nifti/329.nii.gz\n",
      "Failed to process nifti/355.nii.gz\n",
      "Failed to process nifti/45.nii.gz\n",
      "Failed to process nifti/76.nii.gz\n",
      "Failed to process nifti/89.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(patients)):\n",
    "    try:\n",
    "        mark_nifti(patients, i, patient_data)\n",
    "    except KeyError:\n",
    "        print(\"Failed to process {}\".format(patients[i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "moani_bootcamp_2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
